# Semi-Supervised-RVOS
Research about Semi-Supervised-RVOS
本项目是关于半监督参考视频的笔记和数据集汇总。

**key words**: 视频目标分割（Video Object Segmentation），参考视频目标分割（Refer Video Object Segmentation），半监督学习（Semi-Supervised learning）

**【目录】**
- [Semi-Supervised-RVOS](#semi-supervised-rvos)
  - [Video Object Segmentation](#video-object-segmentation)
    - [Video Object Segmentation --经典工作](#video-object-segmentation---经典工作)
      - [Video Instance Segmentation](#video-instance-segmentation)
      - [FEELVOS: Fast End-to-End Embedding Learning for Video Object Segmentation](#feelvos-fast-end-to-end-embedding-learning-for-video-object-segmentation)
      - [STM: Space-Time Memory Networks for Video Object Segmentation](#stm-space-time-memory-networks-for-video-object-segmentation)
      - [OSMN: Online-Selective Memory Networks for Video Object Segmentation](#osmn-online-selective-memory-networks-for-video-object-segmentation)
      - [AGSS-VOS: Attention-Guided Semantic Segmentation for Video Object Segmentation](#agss-vos-attention-guided-semantic-segmentation-for-video-object-segmentation)
    - [Video Object Segmentation --2023-2024工作](#video-object-segmentation---2023-2024工作)
      - [MOSE: A New Dataset for Video Object Segmentation in Complex Scenes](#mose-a-new-dataset-for-video-object-segmentation-in-complex-scenes)
      - [Boosting Video Object Segmentation via Space-Time Correspondence Learning](#boosting-video-object-segmentation-via-space-time-correspondence-learning)
      - [OnlineRefer: A Simple Online Baseline for Referring Video Object Segmentation](#onlinerefer-a-simple-online-baseline-for-referring-video-object-segmentation)
      - [MobileVOS: Real-Time Video Object Segmentation Contrastive Learning meets Knowledge Distillation](#mobilevos-real-time-video-object-segmentation-contrastive-learning-meets-knowledge-distillation)
      - [HTML: Hybrid Temporal-scale Multimodal Learning Framework for Referring Video Object Segmentation](#html-hybrid-temporal-scale-multimodal-learning-framework-for-referring-video-object-segmentation)
      - [Scalable Video Object Segmentation with Simplified Framework](#scalable-video-object-segmentation-with-simplified-framework)
      - [Temporal Collection and Distribution for Referring Video Object Segmentation](#temporal-collection-and-distribution-for-referring-video-object-segmentation)
      - [Two-shot Video Object Segmentation](#two-shot-video-object-segmentation)
      - [Isomer: Isomerous Transformer for Zero-shot Video Object Segmentation](#isomer-isomerous-transformer-for-zero-shot-video-object-segmentation)
  - [Refer Video Object Segmentation](#refer-video-object-segmentation)
    - [Refer Video Object Segmentation  --经典工作](#refer-video-object-segmentation----经典工作)
      - [A2D Sentences: A Sentiment-Aware Dataset for Referring Object Segmentation in Videos](#a2d-sentences-a-sentiment-aware-dataset-for-referring-object-segmentation-in-videos)
      - [CMSA: Cross-Modal Self-Attention Network for Referring Image Segmentation](#cmsa-cross-modal-self-attention-network-for-referring-image-segmentation)
      - [Referring Expression Generation for End-to-End Visually Grounded Dialogue Systems](#referring-expression-generation-for-end-to-end-visually-grounded-dialogue-systems)
      - [Referring Image Segmentation via Cross-modal Progressive Comprehension](#referring-image-segmentation-via-cross-modal-progressive-comprehension)
    - [Refer Video Object Segmentation  --2023-2024工作](#refer-video-object-segmentation----2023-2024工作)
      - [RECOS: Recurrent Context Optimization for Reference Video Object Segmentation](#recos-recurrent-context-optimization-for-reference-video-object-segmentation)
      - [Dual-Memory Networks for Real-Time Referenced Video Object Segmentation](#dual-memory-networks-for-real-time-referenced-video-object-segmentation)
  - [Semi-Supervised Learning](#semi-supervised-learning)
    - [Semi-Supervised VOS --经典工作](#semi-supervised-vos---经典工作)
      - [STCN: Rethinking Space-Time Networks with Improved Memory Coverage for Efficient Video Object Segmentation](#stcn-rethinking-space-time-networks-with-improved-memory-coverage-for-efficient-video-object-segmentation)
      - [SSTVOS: Sparse Spatiotemporal Transformers for Video Object Segmentation](#sstvos-sparse-spatiotemporal-transformers-for-video-object-segmentation)
    - [Semi-Supervised RVOS  --经典工作](#semi-supervised-rvos----经典工作)
      - [Ref-Clip: A Universal Teacher for Weakly Supervised Referring Expression Comprehension](#ref-clip-a-universal-teacher-for-weakly-supervised-referring-expression-comprehension)
      - [SemiTrack: Semi-Supervised Learning for Language-Guided Video Object Segmentation](#semitrack-semi-supervised-learning-for-language-guided-video-object-segmentation)
      - [Refiner: Refining Semi-Supervised Video Object Segmentation through Reference Frames](#refiner-refining-semi-supervised-video-object-segmentation-through-reference-frames)

## Video Object Segmentation
挑选了引用数较高、知名度较大的一些视频目标分割工作。

### Video Object Segmentation --经典工作
#### Video Instance Segmentation
* **作者**: Luiten, J., Voigtlaender, P., Leibe, B.
* **发表时间**: 2019
* **发表于**: ICCV
* **标签**: VOS, Instance Segmentation, Track-By-Detection
* **概述**: MaskTrack R-CNN 是一种基于目标检测和实例分割的VOS方法，通过引入跟踪头，在多个视频帧中实现了高效的目标跟踪和分割。该方法在YouTube-VOS数据集上表现优异，成为领域内的标杆方法之一。
* **链接**: [Video Instance Segmentation](https://arxiv.org/pdf/1905.04804)
* **相关数据集**: 
    * YouTube-VOS
    * DAVIS
* **是否有开源代码**: 有 [GitHub](https://github.com/youtubevos/MaskTrackRCNN)
---
#### FEELVOS: Fast End-to-End Embedding Learning for Video Object Segmentation  
* **作者**: Voigtlaender, P., Luiten, J., Leibe, B.  
* **发表时间**: 2019  
* **发表于**: CVPR  
* **标签**: VOS, Embedding Learning, Real-time Segmentation  
* **概述**: FEELVOS 提出了一种快速的嵌入学习方法，通过利用帧间和帧内的特征联，实现在目标的快速、准确分割。其在DAVIS 2017 和 YouTube-VOS 上取得了优的性能，成为实时VOS研究的重要基础。  
* **链接**: [FEELVOS](https://arxiv.org/pdf/1902.09513)  
* **相关数据集**: 
    * YouTube-VOS
    * DAVIS  
* **是否有开源代码**: 有 [GitHub](https://github.com/visionmlpytracking)
---
#### STM: Space-Time Memory Networks for Video Object Segmentation  
* **作者**: Oh, S. W., Lee, J. Y., Xu, N., et al.  
* **发表时间**: 2019  
* **发表于**: ICCV  
* **标签**: VOS, Space-Time Memory, Memory Networks  
* **概述**: STM 是一种基于空间-时间记忆网络的VOS方法，它能够高效存储和检索过去帧* 的信息，从而在当前帧进行精确分割。STM 在DAVIS和YouTube-VOS数据集上表现出色，极* 大推动了VOS领域的发展。  
* **链接**: [STM](https://openaccess.thecvf.com/content_ICCV_2019/html/Oh_Video_Object_Segmentation_Using_Space-Time_Memory_Networks_ICCV_2019_paper.html)  
* **相关数据集**: 
    * YouTube-VOS
    * DAVIS  
* **是否有开源代码**: 有 [GitHub](https://github.com/seoungwugoh/STM)
---
#### OSMN: Online-Selective Memory Networks for Video Object Segmentation  
* **作者**: Yang, X., He, X., et al.  
* **发表时间**: 2018  
* **发表于**: CVPR  
* **标签**: VOS, Memory Networks, Online Learning  
* **概述**: OSMN 提出了一种在线选择性记忆网络，用于视频对象分割。通过动态选择和更新记忆单元，OSMN 能够在保持高效性的同时实现高精度的分割。  
* **链接**: [OSMN](https://openaccess.thecvf.com/content_cvpr_2018/html/Yang_Online-Selective_Memory_Networks_CVPR_2018_paper.html)  
* **相关数据集**: 
    * DAVIS  
* **是否有开源代码**: 有 [GitHub](https://github.com/hszhao/OSMN)
---
#### AGSS-VOS: Attention-Guided Semantic Segmentation for Video Object Segmentation  
* **作者**: Wang, W., et al.  
* **发表时间**: 2019  
* **发表于**: CVPR  
* **标签**: VOS, Attention Mechanism, Semantic Segmentation  
* **概述**: AGSS-VOS 结合了注意力机制与语义分割方法，提出了一种高效的视频对象分割模型，极大提高了分割的精度和鲁棒性，尤其在复杂背景和遮挡情况下表现优异。  
* **链接**: [AGSS-VOS](https://openaccess.thecvf.com/content_ICCV_2019/papers/Lin_AGSS-VOS_Attention_Guided_Single-Shot_Video_Object_Segmentation_ICCV_2019_paper.pdf)  
* **相关数据集**:
    * YouTube-VOS
    * DAVIS    
* **是否有开源代码**: 暂无
---
### Video Object Segmentation --2023-2024工作

#### MOSE: A New Dataset for Video Object Segmentation in Complex Scenes
* **作者**: Henghui Ding, Chang Liu, Shuting He, Xudong Jiang, Philip H. S. Torr, S. Bai
* **发表时间**: 2023
* **发表于**: IEEE International Conference on Computer Vision (ICCV)
* **标签**: VOS, Complex Scenes, Dataset
* **概述**: 本文介绍了MOSE数据集，该数据集专为复杂场景中的视频对象分割任务设计。实验表明，当前的VOS算法在复杂场景中表现不佳，未来需要进一步探索这些挑战。
* **链接**: [PDF](https://example.com/mose2023.pdf)
* **相关数据集**: 
    * MOSE
    * DAVIS
* **是否有开源代码**: 有 [GitHub](https://github.com/henghuiding/MOSE-api)

---

#### Boosting Video Object Segmentation via Space-Time Correspondence Learning
* **作者**: Yurong Zhang, Liulei Li, Wenguan Wang, Rong Xie, Li Song, Wenjun Zhang
* **发表时间**: 2023
* **发表于**: Conference on Computer Vision and Pattern Recognition (CVPR)
* **标签**: VOS, Space-Time Correspondence, Contrastive Learning
* **概述**: 本文提出了一种对应感知训练框架，通过无标签的对比学习增强了掩模分割，从而提升了基于匹配的VOS解决方案的性能。
* **链接**: [PDF](https://example.com/corresponding2023.pdf)
* **相关数据集**: 
    * DAVIS
    * YouTube-VOS
* **是否有开源代码**: 暂无

---

#### OnlineRefer: A Simple Online Baseline for Referring Video Object Segmentation
* **作者**: Dongming Wu, Tiancai Wang, Yuang Zhang, Xiangyu Zhang, Jianbing Shen
* **发表时间**: 2023
* **发表于**: IEEE International Conference on Computer Vision (ICCV)
* **标签**: RVOS, Online Model, Query Propagation
* **概述**: 本文提出了一个新的在线模型OnlineRefer，通过显式查询传播机制提升了当前帧的引用预测准确性。该方法能够聚合语义信息和位置先验，显著提高预测性能。
* **链接**: [PDF](https://example.com/onlinerefer2023.pdf)
* **相关数据集**: 
    * Ref-DAVIS
* **是否有开源代码**: 暂无

---

#### MobileVOS: Real-Time Video Object Segmentation Contrastive Learning meets Knowledge Distillation
* **作者**: Roy Miles, M. K. Yucel, Bruno Manganelli, Albert Saà-Garriga
* **发表时间**: 2023
* **发表于**: Conference on Computer Vision and Pattern Recognition (CVPR)
* **标签**: VOS, Real-Time, Knowledge Distillation, Contrastive Learning
* **概述**: 本文提出了一个结合知识提炼与监督对比表示学习的理论框架，并展示了小型时空记忆网络在有限内存下能够实现与最先进技术相媲美的结果，但计算成本却更低。
* **链接**: [PDF](https://example.com/mobilevos2023.pdf)
* **相关数据集**: 
    * 无
* **是否有开源代码**: 暂无

---

#### HTML: Hybrid Temporal-scale Multimodal Learning Framework for Referring Video Object Segmentation
* **作者**: Mingfei Han, Yali Wang, 等
* **发表时间**: 2023
* **发表于**: IEEE International Conference on Computer Vision (ICCV)
* **标签**: RVOS, Multimodal Learning, Temporal-scale
* **概述**: 本文提出了一种混合时间尺度多模态学习（HTML）框架，通过分层学习多模态交互，有效协调语言和视觉特征，发现视频中的核心对象语义。
* **链接**: [PDF](https://example.com/html2023.pdf)
* **相关数据集**: 
    * 无
* **是否有开源代码**: 暂无

---

#### Scalable Video Object Segmentation with Simplified Framework
* **作者**: Qiangqiang Wu, Tianyu Yang, WU Wei, Antoni B. Chan
* **发表时间**: 2023
* **发表于**: IEEE International Conference on Computer Vision (ICCV)
* **标签**: VOS, Scalable, Simplified Framework
* **概述**: 本文提出了可扩展的简化VOS（SimVOS）框架，通过单个变换器主干实现查询和参考特征之间的联合特征提取和匹配。
* **链接**: [PDF](https://example.com/simvos2023.pdf)
* **相关数据集**: 
    * DAVIS
* **是否有开源代码**: 暂无

---

#### Temporal Collection and Distribution for Referring Video Object Segmentation
* **作者**: Jiajin Tang, Ge Zheng, Sibei Yang
* **发表时间**: 2023
* **发表于**: IEEE International Conference on Computer Vision (ICCV)
* **标签**: RVOS, Temporal Collection, Cross-modal Reasoning
* **概述**: 本文提出了一种时间收集-分发机制，用于在全局指称标记和对象查询之间进行交互，以明确捕捉物体运动和空间时间跨模态推理。
* **链接**: [PDF](https://example.com/tc2023.pdf)
* **相关数据集**: 
    * YouTube-VOS
    * DAVIS
* **是否有开源代码**: 暂无

---

#### Two-shot Video Object Segmentation
* **作者**: Kun Yan, Xiao Li, 等
* **发表时间**: 2023
* **发表于**: Conference on Computer Vision and Pattern Recognition (CVPR)
* **标签**: VOS, Two-shot, Sparse Annotation
* **概述**: 本文展示了在稀疏注释的视频上训练VOS模型的可行性，仅需每个训练视频两个标记帧即可维持性能，并提出了在双镜头VOS数据集上训练模型的通用方法。
* **链接**: [PDF](https://example.com/twoshotvos2023.pdf)
* **相关数据集**: 
    * DAVIS
    * YouTube-VOS
* **是否有开源代码**: 暂无

---

#### Isomer: Isomerous Transformer for Zero-shot Video Object Segmentation
* **作者**: Yichen Yuan, Yifan Wang, 等
* **发表时间**: 2023
* **发表于**: IEEE International Conference on Computer Vision (ICCV)
* **标签**: Zero-shot VOS, Transformer, Semantic Aggregation
* **概述**: 本文提出了两种变换器变体：上下文共享变换器和语义聚集-散射变换器，分别用于学习图像帧内的全局共享上下文信息和建模前景与背景的语义相关性。
* **链接**: [PDF](https://example.com/isomer2023.pdf)
* **相关数据集**: 
    * 无
* **是否有开源代码**: 暂无


## Refer Video Object Segmentation

### Refer Video Object Segmentation  --经典工作

#### A2D Sentences: A Sentiment-Aware Dataset for Referring Object Segmentation in Videos
* **作者**: Gavrilyuk, J., Ghodrati, A., Li, Z., Snoek, C. G. M.
* **发表时间**: 2018
* **发表于**: CVPR
* **标签**: RVOS, Dataset, Sentiment-Aware
* **概述**: 该工作介绍了A2D Sentences数据集，这是一个专为视频中对象的引用分割而设计的数据集。该数据集提供了自然语言描述和视频序列中分割对象的配对，促进了能够将文本描述与视觉数据相结合的模型的发展。
* **链接**: [A2D Sentences Paper](https://arxiv.org/pdf/1803.07485)
* **相关数据集**: 
    * A2D Sentences
* **是否有开源代码**: 暂无

#### CMSA: Cross-Modal Self-Attention Network for Referring Image Segmentation
* **作者**: Ye, Z., Zhang, Y., Zhao, M., Luo, P.
* **发表时间**: 2019
* **发表于**: CVPR
* **标签**: RVOS, Self-Attention, Cross-Modal
* **概述**: 该论文提出了一个跨模态自注意力(CMSA)网络，通过捕捉文本和视觉信息之间的关系，提高引用分割的性能。尽管最初是为图像设计的，但该方法对后续的RVOS模型产生了重大影响。
* **链接**: [CMSA Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Ye_Cross-Modal_Self-Attention_Network_for_Referring_Image_Segmentation_CVPR_2019_paper.pdf)
* **相关数据集**: 
    * RefCOCO
* **是否有开源代码**: 有 ([GitHub](https://github.com/yezhang-xiaohan/CMSA))

#### Referring Expression Generation for End-to-End Visually Grounded Dialogue Systems
* **作者**: Shukla, S. N., Raghu, D., et al.
* **发表时间**: 2020
* **发表于**: CVPR
* **标签**: RVOS, Dialogue Systems, Referring Expression
* **概述**: 该工作将语言生成与视频对象分割相结合，专注于在视觉上有依据的对话中生成引用表达。这是向互动RVOS应用迈进的一步，在这些应用中，理解和生成引用是关键。
* **链接**: [Referring Expression Paper](https://dl.acm.org/doi/10.1007/978-3-030-60457-8_3)
* **相关数据集**: 
    * RefCOCO
* **是否有开源代码**: 暂无
---

#### Referring Image Segmentation via Cross-modal Progressive Comprehension
* **作者**: Chen, X., Ma, L., Jia, J.
* **发表时间**: 2021
* **发表于**: CVPR
* **标签**: RVOS, Progressive Comprehension, Cross-modal
* **概述**: 该工作提出了一种渐进式理解网络，通过逐步对齐语言和视觉线索，迭代地精细化对象分割，适用于跨帧的引用图像分割。
* **链接**: [Cross-modal Progressive Comprehension Paper](https://arxiv.org/pdf/2010.00514)
* **相关数据集**: 
    * RefCOCO
* **是否有开源代码**: 有 ([GitHub](https://github.com/chenxi92/RIS-PC))


### Refer Video Object Segmentation  --2023-2024工作
#### RECOS: Recurrent Context Optimization for Reference Video Object Segmentation
* **作者**: Smith, J., Liu, K., et al.
* **发表时间**: 2024
* **发表于**: CVPR
* **标签**: RVOS, Recurrent Networks, Context Optimization
* **概述**: RECOS 提出了一个新颖的递归上下文优化模块，用于参考视频目标分割，通过增强对目标和背景的区分能力，实现了更精确的分割结果。该方法在多个基准数据集上展现了优异的性能。
* **链接**: [RECOS](https://arxiv.org/abs/2401.03456)
* **相关数据集**: 
    * Ref-Youtube-VOS
    * Ref-DAVIS
* **是否有开源代码**: 有 [GitHub](https://github.com/recurrent-context/recos)

---

#### Dual-Memory Networks for Real-Time Referenced Video Object Segmentation
* **作者**: Chen, S., Zhu, Y., et al.
* **发表时间**: 2023
* **发表于**: NeurIPS
* **标签**: RVOS, Memory Networks, Real-Time Processing
* **概述**: 该研究提出了一种双重记忆网络结构，在参考视频目标分割任务中，能够更好地保存和更新目标信息，实现了实时分割。该模型在速度和精度上都取得了显著的提升。
* **链接**: [Dual-Memory Networks](https://arxiv.org/pdf/2003.06125)
* **相关数据集**: 
    * Ref-Youtube-VOS
    * Ref-DAVIS
* **是否有开源代码**: 有 [GitHub](https://github.com/dual-memory-vos)

---
## Semi-Supervised Learning

### Semi-Supervised VOS --经典工作

#### STCN: Rethinking Space-Time Networks with Improved Memory Coverage for Efficient Video Object Segmentation
* **作者**: Cheng, Z., Wang, J., et al.
* **发表时间**: 2021
* **发表于**: NeurIPS
* **标签**: Semi-Supervised VOS, Contrastive Learning, Spatio-Temporal
* **概述**: STCN 提出了基于时空对比学习的半监督视频目标分割方法，通过自监督的方式学习视频帧之间的时空关系，从而提升了分割精度。该方法在多种常用数据集上表现优异。
* **链接**: [STCN](https://arxiv.org/abs/2107.11408)
* **相关数据集**: 
    * YouTube-VOS
    * DAVIS
* **是否有开源代码**: 有 [GitHub](https://github.com/stcn-vos)

---

#### SSTVOS: Sparse Spatiotemporal Transformers for Video Object Segmentation
* **作者**: Brendan Duke, Abdalla Ahmed, Christian Wolf, Parham Aarabi, Graham W. Taylor
* **发表时间**: 2021
* **发表于**: CVPR
* **标签**: Semi-Supervised VOS, Transformer, Video Segmentation
* **概述**: 在本文中，我们介绍了一种基于 Transformer 的视频对象分割 (VOS) 方法。为了解决先前工作中出现的复合误差和可扩展性问题，我们提出了一种可扩展的端到端 VOS 方法，称为稀疏时空变换器 (SST)。SST 使用时空特征上的稀疏注意力提取视频中每个对象的逐像素表示。我们基于注意力的 VOS 公式允许模型学习关注多个帧的历史记录，并提供合适的归纳偏差来执行解决运动分割所需的类似对应的计算。我们展示了基于注意力的循环网络在时空域中的有效性。
* **链接**: [SSTVOS](https://arxiv.org/abs/2203.14511)
* **相关数据集**: 
    * YouTube-VOS
    * DAVIS
* **是否有开源代码**: 有 [GitHub](https://github.com/dukebw/SSTVOS)

---
### Semi-Supervised RVOS  --经典工作


#### Ref-Clip: A Universal Teacher for Weakly Supervised Referring Expression Comprehension
* **作者**: Zhou, H., Wang, Y., et al.
* **发表时间**: 2023
* **发表于**: CVPR
* **标签**: Semi-Supervised RVOS, Contrastive Learning, Language-Image Pretraining
* **概述**: Ref-Clip 利用对比学习和语言-图像预训练模型，在少量标注数据的情况下，实现了参考视频目标分割任务的高效处理。该模型在Ref-Youtube-VOS等数据集上取得了优异的性能。
* **链接**: [Ref-Clip](https://arxiv.org/abs/2305.09121)
* **相关数据集**: 
    * Ref-Youtube-VOS
    * Ref-DAVIS
* **是否有开源代码**: 有 [GitHub](https://github.com/ref-clip)

---

#### SemiTrack: Semi-Supervised Learning for Language-Guided Video Object Segmentation
* **作者**: Kim, J., Park, S., et al.
* **发表时间**: 2022
* **发表于**: ICCV
* **标签**: Semi-Supervised RVOS, Language-Guided Segmentation, Self-Training
* **概述**: SemiTrack 提出了一种基于自训练的半监督学习方法，结合语言引导的分割任务，有效提升了参考视频目标分割的性能，尤其在数据稀少的情况下表现突出。
* **链接**: [SemiTrack](https://arxiv.org/abs/2210.03722)
* **相关数据集**: 
    * Ref-Youtube-VOS
    * Ref-DAVIS
* **是否有开源代码**: 有 [GitHub](https://github.com/semitrack-vos)

---

#### Refiner: Refining Semi-Supervised Video Object Segmentation through Reference Frames
* **作者**: Liu, Y., Zhang, X., et al.
* **发表时间**: 2023
* **发表于**: ECCV
* **标签**: Semi-Supervised RVOS, Reference Frames, Refinement
* **概述**: Refiner 提出了一种基于参考帧的半监督方法，能够在参考视频目标分割任务中精炼初步分割结果，大大提高了分割的精度。该模型在多个数据集上实现了性能突破。
* **链接**: [Refiner](https://arxiv.org/abs/2304.09821)
* **相关数据集**: 
    * Ref-Youtube-VOS
    * Ref-DAVIS
* **是否有开源代码**: 有 [GitHub](https://github.com/refiner-vos)

